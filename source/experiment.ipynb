{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plotter\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./TrafficTwoMonth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>CarCount</th>\n",
       "      <th>BikeCount</th>\n",
       "      <th>BusCount</th>\n",
       "      <th>TruckCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>Traffic Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12:15:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12:30:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12:45:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>10:45:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>11:00:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>11:15:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>11:30:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>11:45:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time  Date Day of the week  CarCount  BikeCount  BusCount  \\\n",
       "0     12:00:00 AM    10         Tuesday        13          2         2   \n",
       "1     12:15:00 AM    10         Tuesday        14          1         1   \n",
       "2     12:30:00 AM    10         Tuesday        10          2         2   \n",
       "3     12:45:00 AM    10         Tuesday        10          2         2   \n",
       "4      1:00:00 AM    10         Tuesday        11          2         1   \n",
       "...           ...   ...             ...       ...        ...       ...   \n",
       "5947  10:45:00 PM     9        Thursday        16          3         1   \n",
       "5948  11:00:00 PM     9        Thursday        11          0         1   \n",
       "5949  11:15:00 PM     9        Thursday        15          4         1   \n",
       "5950  11:30:00 PM     9        Thursday        16          5         0   \n",
       "5951  11:45:00 PM     9        Thursday        14          3         1   \n",
       "\n",
       "      TruckCount  Total Traffic Situation  \n",
       "0             24     41            normal  \n",
       "1             36     52            normal  \n",
       "2             32     46            normal  \n",
       "3             36     50            normal  \n",
       "4             34     48            normal  \n",
       "...          ...    ...               ...  \n",
       "5947          36     56            normal  \n",
       "5948          30     42            normal  \n",
       "5949          25     45            normal  \n",
       "5950          27     48            normal  \n",
       "5951          15     33               low  \n",
       "\n",
       "[5952 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target của dataset này là \"Traffic Situation\" trong đó có 4 lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heavy', 'high', 'low', 'normal'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['Traffic Situation'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tách thành tập train và test, để dành cho việc tách tập train thành 1 tập validation sau này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = train_test_split(df, test_size=0.25,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train:  (4464, 9)\n",
      "Shape of test (1488, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train: \", Train.shape)\n",
    "print(\"Shape of test\", Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biểu đồ dưới đây nhằm mục đích đánh số cho các feature và target thuộc categorical là \"Day of the week\" và \"Traffic Situation\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "sns.countplot(x = Train[\"Day of the week\"])\n",
    "plotter.xticks(rotation = 90)\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(x = Train[\"Traffic Situation\"])\n",
    "plotter.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong dataset này 2 categorial features là \"Time\" và \"Day of the week\" và một target cũng có categorical.\\\n",
    "Thông thường với các categorical features dạng thứ thứ bậc ta có thể dùng OrdinalEncoder trong sklearn để thực hiện việc encode. \\\n",
    "OrdinalEncoder giúp ta có thể encode n categories trong 1 categorical feature thành các số nguyên từ 0 đến n - 1. \\\n",
    "Tuy nhiên, OrdinalEncoder encode các categories một cách ngẫu nhiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Monday -> Encode [[1.]]\n",
      "Category: Tuesday -> Encode [[5.]]\n",
      "Category: Wednesday -> Encode [[6.]]\n",
      "Category: Thursday -> Encode [[4.]]\n",
      "Category: Friday -> Encode [[0.]]\n",
      "Category: Saturday -> Encode [[2.]]\n",
      "Category: Sunday -> Encode [[3.]]\n"
     ]
    }
   ],
   "source": [
    "tmpTrain = Train\n",
    "\n",
    "enc  = OrdinalEncoder()\n",
    "enc.fit_transform(np.array([tmpTrain['Day of the week']]).reshape(-1, 1))\n",
    "day_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for day in day_of_week :\n",
    "    print(f'Category: {day} -> Encode {enc.transform(np.array([[day]]).reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì mục tiêu là dự đoán chính xác, chúng tôi cài đặt thủ công về việc encode \"Day of the week\" thủ công. \\\n",
    "Tương tự đối với target \"Traffic Situation\", ta cũng có thể encode bằng LabelEncoder trong sklearn, tuy nhiên vẫn phải encode thủ công.\\\n",
    "Còn với feature \"Time\" ta có thể dùng OrdinalEncoder (hoặc LabelEncoder) để thực hiện encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week_enc = {\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "\n",
    "traffic_sistuation = {\n",
    "    'low': 0,\n",
    "    'normal': 1,\n",
    "    'high': 2, \n",
    "    'heavy':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "\n",
    "df_temp_Train = Train\n",
    "df_temp_Test = Test\n",
    "\n",
    "df_temp_Train['Day of the week'] = df_temp_Train['Day of the week'].replace(day_of_week_enc)\n",
    "df_temp_Train['Time'] =  enc.fit_transform(np.array([df_temp_Train['Time']]).reshape(-1, 1)).reshape(-1)\n",
    "df_temp_Train['Traffic Situation'] = df_temp_Train['Traffic Situation'].replace(traffic_sistuation)\n",
    "\n",
    "df_temp_Test['Day of the week'] = df_temp_Test['Day of the week'].replace(day_of_week_enc)\n",
    "df_temp_Test['Time'] =  enc.transform(np.array([df_temp_Test['Time']]).reshape(-1, 1)).reshape(-1)\n",
    "df_temp_Test['Traffic Situation'] = df_temp_Test['Traffic Situation'].replace(traffic_sistuation)\n",
    "\n",
    "Train = df_temp_Train\n",
    "Test = df_temp_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>CarCount</th>\n",
       "      <th>BikeCount</th>\n",
       "      <th>BusCount</th>\n",
       "      <th>TruckCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>Traffic Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>94.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>11.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>32.0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>59.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5809</th>\n",
       "      <td>19.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>48.0</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>75.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>9.0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>11.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  Date  Day of the week  CarCount  BikeCount  BusCount  TruckCount  \\\n",
       "5703  94.0     7                2        31         10        40           9   \n",
       "521    2.0    15                7        46          5        11          13   \n",
       "2013  11.0    30                1         9          1         0          31   \n",
       "4808  32.0    29                7        18          4         1          31   \n",
       "5637  59.0     6                1       119         28        46           9   \n",
       "...    ...   ...              ...       ...        ...       ...         ...   \n",
       "5809  19.0     8                3        69         10         4          24   \n",
       "4720  48.0    28                6        18          3         0          17   \n",
       "173   75.0    11                3        72          1         9          32   \n",
       "1244   9.0    22                7         8          1         1          22   \n",
       "4989  11.0    30                1        14          1         0          27   \n",
       "\n",
       "      Total  Traffic Situation  \n",
       "5703     90                  1  \n",
       "521      75                  0  \n",
       "2013     41                  1  \n",
       "4808     54                  1  \n",
       "5637    202                  3  \n",
       "...     ...                ...  \n",
       "5809    107                  1  \n",
       "4720     38                  0  \n",
       "173     114                  2  \n",
       "1244     32                  1  \n",
       "4989     42                  1  \n",
       "\n",
       "[4464 rows x 9 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi đã thực hiện việc encode các categorical features. Bước tiếp theo là scale data về một khoảng nào đó để dễ tính toán.\\\n",
    "Chúng tôi, xin sử dụng StandardScaler trong sklearn đễ thực hiện.\\\n",
    "Đầu tiên cần tách thêm một lần nữa 2 tập Train, Test thành X_Train, y_train, X_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.drop(['Traffic Situation'], axis=1).values\n",
    "y_train = Train['Traffic Situation'].values\n",
    "\n",
    "X_test = Test.drop(['Traffic Situation'], axis=1).values\n",
    "y_test = Test['Traffic Situation'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[ 94.   7.   2. ...  40.   9.  90.]\n",
      " [  2.  15.   7. ...  11.  13.  75.]\n",
      " [ 11.  30.   1. ...   0.  31.  41.]\n",
      " ...\n",
      " [ 75.  11.   3. ...   9.  32. 114.]\n",
      " [  9.  22.   7. ...   1.  22.  32.]\n",
      " [ 11.  30.   1. ...   0.  27.  42.]]\n",
      "================================================================\n",
      "y_train:\n",
      "[1 0 1 ... 2 1 1]\n",
      "================================================================\n",
      "X_test:\n",
      "[[ 85.  28.   6. ...  15.  32. 129.]\n",
      " [ 17.  22.   7. ...   1.  26.  91.]\n",
      " [ 69.   7.   2. ...  11.  32. 108.]\n",
      " ...\n",
      " [ 95.  29.   7. ...   2.  29.  38.]\n",
      " [ 57.  16.   1. ...  33.  13. 184.]\n",
      " [  2.  20.   5. ...  16.  10. 153.]]\n",
      "================================================================\n",
      "y_test:\n",
      "[2 1 1 ... 1 3 1]\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "print('X_train:')\n",
    "print(X_train)\n",
    "print('='*64)\n",
    "\n",
    "print('y_train:')\n",
    "print(y_train)\n",
    "print('='*64)\n",
    "\n",
    "print('X_test:')\n",
    "print(X_test)\n",
    "print('='*64)\n",
    "\n",
    "print('y_test:')\n",
    "print(y_test)\n",
    "print('='*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo đây sẽ scale các tập X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.690340</td>\n",
       "      <td>-1.001728</td>\n",
       "      <td>-0.981514</td>\n",
       "      <td>-0.775747</td>\n",
       "      <td>-0.191491</td>\n",
       "      <td>2.178304</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>-0.347881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.647204</td>\n",
       "      <td>-0.106490</td>\n",
       "      <td>1.603734</td>\n",
       "      <td>-0.440935</td>\n",
       "      <td>-0.628289</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.514344</td>\n",
       "      <td>-0.616231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.320705</td>\n",
       "      <td>1.572081</td>\n",
       "      <td>-1.498563</td>\n",
       "      <td>-1.266804</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-1.036118</td>\n",
       "      <td>1.137213</td>\n",
       "      <td>-1.224491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.558874</td>\n",
       "      <td>1.460176</td>\n",
       "      <td>1.603734</td>\n",
       "      <td>-1.065917</td>\n",
       "      <td>-0.715648</td>\n",
       "      <td>-0.955758</td>\n",
       "      <td>1.137213</td>\n",
       "      <td>-0.991921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420622</td>\n",
       "      <td>-1.113633</td>\n",
       "      <td>-1.498563</td>\n",
       "      <td>1.188481</td>\n",
       "      <td>1.380983</td>\n",
       "      <td>2.660467</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>1.655799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>-1.030484</td>\n",
       "      <td>-0.889823</td>\n",
       "      <td>-0.464464</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>-0.191491</td>\n",
       "      <td>-0.714676</td>\n",
       "      <td>0.494941</td>\n",
       "      <td>-0.043751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0.021568</td>\n",
       "      <td>1.348271</td>\n",
       "      <td>1.086684</td>\n",
       "      <td>-1.065917</td>\n",
       "      <td>-0.803008</td>\n",
       "      <td>-1.036118</td>\n",
       "      <td>-0.147331</td>\n",
       "      <td>-1.278161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>1.001065</td>\n",
       "      <td>-0.554109</td>\n",
       "      <td>-0.464464</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-0.312873</td>\n",
       "      <td>1.228966</td>\n",
       "      <td>0.081479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>-1.393260</td>\n",
       "      <td>0.676843</td>\n",
       "      <td>1.603734</td>\n",
       "      <td>-1.289125</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-0.955758</td>\n",
       "      <td>0.311434</td>\n",
       "      <td>-1.385501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>-1.320705</td>\n",
       "      <td>1.572081</td>\n",
       "      <td>-1.498563</td>\n",
       "      <td>-1.155200</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-1.036118</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>-1.206601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     1.690340 -1.001728 -0.981514 -0.775747 -0.191491  2.178304 -0.881356   \n",
       "1    -1.647204 -0.106490  1.603734 -0.440935 -0.628289 -0.152152 -0.514344   \n",
       "2    -1.320705  1.572081 -1.498563 -1.266804 -0.977727 -1.036118  1.137213   \n",
       "3    -0.558874  1.460176  1.603734 -1.065917 -0.715648 -0.955758  1.137213   \n",
       "4     0.420622 -1.113633 -1.498563  1.188481  1.380983  2.660467 -0.881356   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4459 -1.030484 -0.889823 -0.464464  0.072443 -0.191491 -0.714676  0.494941   \n",
       "4460  0.021568  1.348271  1.086684 -1.065917 -0.803008 -1.036118 -0.147331   \n",
       "4461  1.001065 -0.554109 -0.464464  0.139405 -0.977727 -0.312873  1.228966   \n",
       "4462 -1.393260  0.676843  1.603734 -1.289125 -0.977727 -0.955758  0.311434   \n",
       "4463 -1.320705  1.572081 -1.498563 -1.155200 -0.977727 -1.036118  0.770200   \n",
       "\n",
       "             7  \n",
       "0    -0.347881  \n",
       "1    -0.616231  \n",
       "2    -1.224491  \n",
       "3    -0.991921  \n",
       "4     1.655799  \n",
       "...        ...  \n",
       "4459 -0.043751  \n",
       "4460 -1.278161  \n",
       "4461  0.081479  \n",
       "4462 -1.385501  \n",
       "4463 -1.206601  \n",
       "\n",
       "[4464 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng các models học máy cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì vấn đề trong bài toán này là Classification, nên chúng tôi sẽ sử dụng các mô hình học máy giải quyết về vấn đề classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng tôi cũng sử dụng classification_report để đáng giá các model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để đảm bảo tính công bằng các model sẽ không được cài đặt (configure) các tham số mà chỉ để các tham số ở mặc định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    KNeighborsClassifier(), \n",
    "    LogisticRegression(), \n",
    "    GaussianNB(), \n",
    "    RandomForestClassifier(), \n",
    "    AdaBoostClassifier(), \n",
    "    GradientBoostingClassifier(), \n",
    "    BaggingClassifier(), \n",
    "    SVC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       219\n",
      "           1       0.90      0.96      0.93       874\n",
      "           2       0.76      0.49      0.60       110\n",
      "           3       0.93      0.93      0.93       285\n",
      "\n",
      "    accuracy                           0.90      1488\n",
      "   macro avg       0.88      0.81      0.84      1488\n",
      "weighted avg       0.90      0.90      0.90      1488\n",
      "\n",
      "================================================================\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.78       219\n",
      "           1       0.87      0.94      0.91       874\n",
      "           2       0.77      0.40      0.53       110\n",
      "           3       0.96      0.98      0.97       285\n",
      "\n",
      "    accuracy                           0.88      1488\n",
      "   macro avg       0.86      0.77      0.80      1488\n",
      "weighted avg       0.88      0.88      0.87      1488\n",
      "\n",
      "================================================================\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81       219\n",
      "           1       0.87      0.82      0.84       874\n",
      "           2       0.33      0.56      0.42       110\n",
      "           3       0.87      0.99      0.93       285\n",
      "\n",
      "    accuracy                           0.81      1488\n",
      "   macro avg       0.77      0.76      0.75      1488\n",
      "weighted avg       0.85      0.81      0.82      1488\n",
      "\n",
      "================================================================\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       219\n",
      "           1       1.00      1.00      1.00       874\n",
      "           2       0.99      0.98      0.99       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00      1488\n",
      "   macro avg       1.00      0.99      1.00      1488\n",
      "weighted avg       1.00      1.00      1.00      1488\n",
      "\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       219\n",
      "           1       0.76      1.00      0.87       874\n",
      "           2       1.00      0.53      0.69       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           0.82      1488\n",
      "   macro avg       0.69      0.63      0.64      1488\n",
      "weighted avg       0.71      0.82      0.75      1488\n",
      "\n",
      "================================================================\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       219\n",
      "           1       1.00      1.00      1.00       874\n",
      "           2       1.00      1.00      1.00       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00      1488\n",
      "   macro avg       1.00      1.00      1.00      1488\n",
      "weighted avg       1.00      1.00      1.00      1488\n",
      "\n",
      "================================================================\n",
      "BaggingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       219\n",
      "           1       1.00      1.00      1.00       874\n",
      "           2       1.00      0.99      1.00       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00      1488\n",
      "   macro avg       1.00      1.00      1.00      1488\n",
      "weighted avg       1.00      1.00      1.00      1488\n",
      "\n",
      "================================================================\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       219\n",
      "           1       0.94      0.97      0.95       874\n",
      "           2       0.90      0.65      0.76       110\n",
      "           3       0.95      0.99      0.97       285\n",
      "\n",
      "    accuracy                           0.94      1488\n",
      "   macro avg       0.94      0.88      0.90      1488\n",
      "weighted avg       0.94      0.94      0.94      1488\n",
      "\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('='*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các mô hình Học Máy cơ bản có tỉ lệ dự đoán đúng cao, ví dụ như ở chỉ số accurancy của các mô hình luôn nằm trong khoảng từ 0.8 đến 1.0.\\\n",
    "Trong đó các mô hình dự đoán cao nhất có accuracy là 1.0 là Random Forest Classifier, Gradient Boosting Classifier, Bagging Classifier.\\\n",
    "Tiếp theo hãy thực nghiệm dữ liệu với Feed Forward Neural Network và Recurrent Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng Feed Forward Neural Network và Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward Neural Network (FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax') # target có 4 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì vấn đề là classification, và output layer có activation là softmax, nên target cần phải encode theo onehot (có thể dùng dummy, hoặc to_categorial của keras.utils).\\\n",
    "Ở đây chúng tôi xin sử dụng to_categorical trong keras.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from keras.utils import to_categorical\n",
    "y_train_tmp = copy.copy(y_train)\n",
    "y_train_tmp = to_categorical(y_train_tmp)\n",
    "y_train_onehot = y_train_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 - 2s - loss: 1.2602 - accuracy: 0.4288 - 2s/epoch - 37ms/step\n",
      "Epoch 2/200\n",
      "45/45 - 0s - loss: 0.8613 - accuracy: 0.6969 - 135ms/epoch - 3ms/step\n",
      "Epoch 3/200\n",
      "45/45 - 0s - loss: 0.6979 - accuracy: 0.7341 - 216ms/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "45/45 - 0s - loss: 0.5859 - accuracy: 0.7843 - 136ms/epoch - 3ms/step\n",
      "Epoch 5/200\n",
      "45/45 - 0s - loss: 0.4981 - accuracy: 0.8300 - 110ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "45/45 - 0s - loss: 0.4296 - accuracy: 0.8593 - 111ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "45/45 - 0s - loss: 0.3769 - accuracy: 0.8707 - 124ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "45/45 - 0s - loss: 0.3379 - accuracy: 0.8828 - 172ms/epoch - 4ms/step\n",
      "Epoch 9/200\n",
      "45/45 - 0s - loss: 0.3083 - accuracy: 0.8893 - 284ms/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "45/45 - 0s - loss: 0.2871 - accuracy: 0.8985 - 128ms/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "45/45 - 0s - loss: 0.2713 - accuracy: 0.9028 - 213ms/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "45/45 - 0s - loss: 0.2584 - accuracy: 0.9079 - 226ms/epoch - 5ms/step\n",
      "Epoch 13/200\n",
      "45/45 - 0s - loss: 0.2466 - accuracy: 0.9131 - 173ms/epoch - 4ms/step\n",
      "Epoch 14/200\n",
      "45/45 - 0s - loss: 0.2370 - accuracy: 0.9153 - 224ms/epoch - 5ms/step\n",
      "Epoch 15/200\n",
      "45/45 - 0s - loss: 0.2281 - accuracy: 0.9187 - 168ms/epoch - 4ms/step\n",
      "Epoch 16/200\n",
      "45/45 - 0s - loss: 0.2195 - accuracy: 0.9214 - 102ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "45/45 - 0s - loss: 0.2128 - accuracy: 0.9232 - 193ms/epoch - 4ms/step\n",
      "Epoch 18/200\n",
      "45/45 - 0s - loss: 0.2056 - accuracy: 0.9243 - 134ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "45/45 - 0s - loss: 0.2010 - accuracy: 0.9290 - 76ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "45/45 - 0s - loss: 0.1957 - accuracy: 0.9285 - 86ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "45/45 - 0s - loss: 0.1906 - accuracy: 0.9326 - 155ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "45/45 - 0s - loss: 0.1866 - accuracy: 0.9364 - 249ms/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "45/45 - 0s - loss: 0.1825 - accuracy: 0.9384 - 91ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "45/45 - 0s - loss: 0.1788 - accuracy: 0.9388 - 69ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "45/45 - 0s - loss: 0.1755 - accuracy: 0.9395 - 123ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "45/45 - 0s - loss: 0.1710 - accuracy: 0.9406 - 193ms/epoch - 4ms/step\n",
      "Epoch 27/200\n",
      "45/45 - 0s - loss: 0.1689 - accuracy: 0.9429 - 243ms/epoch - 5ms/step\n",
      "Epoch 28/200\n",
      "45/45 - 0s - loss: 0.1659 - accuracy: 0.9447 - 124ms/epoch - 3ms/step\n",
      "Epoch 29/200\n",
      "45/45 - 0s - loss: 0.1624 - accuracy: 0.9438 - 107ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "45/45 - 0s - loss: 0.1604 - accuracy: 0.9449 - 71ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "45/45 - 0s - loss: 0.1577 - accuracy: 0.9462 - 66ms/epoch - 1ms/step\n",
      "Epoch 32/200\n",
      "45/45 - 0s - loss: 0.1555 - accuracy: 0.9483 - 71ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "45/45 - 0s - loss: 0.1523 - accuracy: 0.9478 - 109ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "45/45 - 0s - loss: 0.1503 - accuracy: 0.9512 - 72ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "45/45 - 0s - loss: 0.1482 - accuracy: 0.9514 - 76ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "45/45 - 0s - loss: 0.1461 - accuracy: 0.9539 - 183ms/epoch - 4ms/step\n",
      "Epoch 37/200\n",
      "45/45 - 0s - loss: 0.1446 - accuracy: 0.9539 - 154ms/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "45/45 - 0s - loss: 0.1422 - accuracy: 0.9563 - 219ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "45/45 - 0s - loss: 0.1405 - accuracy: 0.9559 - 91ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "45/45 - 0s - loss: 0.1386 - accuracy: 0.9568 - 65ms/epoch - 1ms/step\n",
      "Epoch 41/200\n",
      "45/45 - 0s - loss: 0.1371 - accuracy: 0.9588 - 78ms/epoch - 2ms/step\n",
      "Epoch 42/200\n",
      "45/45 - 0s - loss: 0.1357 - accuracy: 0.9583 - 239ms/epoch - 5ms/step\n",
      "Epoch 43/200\n",
      "45/45 - 0s - loss: 0.1341 - accuracy: 0.9590 - 127ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "45/45 - 0s - loss: 0.1322 - accuracy: 0.9588 - 99ms/epoch - 2ms/step\n",
      "Epoch 45/200\n",
      "45/45 - 0s - loss: 0.1305 - accuracy: 0.9610 - 89ms/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "45/45 - 0s - loss: 0.1305 - accuracy: 0.9586 - 84ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "45/45 - 0s - loss: 0.1281 - accuracy: 0.9610 - 88ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "45/45 - 0s - loss: 0.1258 - accuracy: 0.9608 - 78ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "45/45 - 0s - loss: 0.1250 - accuracy: 0.9619 - 106ms/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "45/45 - 0s - loss: 0.1241 - accuracy: 0.9619 - 122ms/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "45/45 - 0s - loss: 0.1221 - accuracy: 0.9617 - 184ms/epoch - 4ms/step\n",
      "Epoch 52/200\n",
      "45/45 - 0s - loss: 0.1210 - accuracy: 0.9633 - 102ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "45/45 - 0s - loss: 0.1201 - accuracy: 0.9639 - 97ms/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "45/45 - 0s - loss: 0.1187 - accuracy: 0.9646 - 171ms/epoch - 4ms/step\n",
      "Epoch 55/200\n",
      "45/45 - 0s - loss: 0.1171 - accuracy: 0.9639 - 190ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "45/45 - 0s - loss: 0.1164 - accuracy: 0.9637 - 98ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "45/45 - 0s - loss: 0.1148 - accuracy: 0.9648 - 91ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "45/45 - 0s - loss: 0.1140 - accuracy: 0.9653 - 89ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "45/45 - 0s - loss: 0.1143 - accuracy: 0.9637 - 83ms/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "45/45 - 0s - loss: 0.1131 - accuracy: 0.9662 - 89ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "45/45 - 0s - loss: 0.1110 - accuracy: 0.9653 - 176ms/epoch - 4ms/step\n",
      "Epoch 62/200\n",
      "45/45 - 0s - loss: 0.1092 - accuracy: 0.9682 - 96ms/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "45/45 - 0s - loss: 0.1088 - accuracy: 0.9668 - 93ms/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "45/45 - 0s - loss: 0.1072 - accuracy: 0.9671 - 172ms/epoch - 4ms/step\n",
      "Epoch 65/200\n",
      "45/45 - 0s - loss: 0.1086 - accuracy: 0.9668 - 144ms/epoch - 3ms/step\n",
      "Epoch 66/200\n",
      "45/45 - 0s - loss: 0.1061 - accuracy: 0.9686 - 123ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "45/45 - 0s - loss: 0.1045 - accuracy: 0.9684 - 168ms/epoch - 4ms/step\n",
      "Epoch 68/200\n",
      "45/45 - 0s - loss: 0.1045 - accuracy: 0.9680 - 119ms/epoch - 3ms/step\n",
      "Epoch 69/200\n",
      "45/45 - 0s - loss: 0.1024 - accuracy: 0.9689 - 85ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "45/45 - 0s - loss: 0.1017 - accuracy: 0.9695 - 78ms/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "45/45 - 0s - loss: 0.1011 - accuracy: 0.9691 - 83ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "45/45 - 0s - loss: 0.1005 - accuracy: 0.9704 - 79ms/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "45/45 - 0s - loss: 0.0986 - accuracy: 0.9716 - 78ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "45/45 - 0s - loss: 0.1005 - accuracy: 0.9716 - 84ms/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "45/45 - 0s - loss: 0.0992 - accuracy: 0.9702 - 81ms/epoch - 2ms/step\n",
      "Epoch 76/200\n",
      "45/45 - 0s - loss: 0.0966 - accuracy: 0.9729 - 82ms/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "45/45 - 0s - loss: 0.0955 - accuracy: 0.9720 - 80ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "45/45 - 0s - loss: 0.0953 - accuracy: 0.9722 - 83ms/epoch - 2ms/step\n",
      "Epoch 79/200\n",
      "45/45 - 0s - loss: 0.0945 - accuracy: 0.9738 - 76ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "45/45 - 0s - loss: 0.0936 - accuracy: 0.9724 - 77ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "45/45 - 0s - loss: 0.0925 - accuracy: 0.9733 - 82ms/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "45/45 - 0s - loss: 0.0919 - accuracy: 0.9727 - 85ms/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "45/45 - 0s - loss: 0.0911 - accuracy: 0.9756 - 105ms/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "45/45 - 0s - loss: 0.0902 - accuracy: 0.9754 - 113ms/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "45/45 - 0s - loss: 0.0899 - accuracy: 0.9745 - 190ms/epoch - 4ms/step\n",
      "Epoch 86/200\n",
      "45/45 - 0s - loss: 0.0894 - accuracy: 0.9740 - 168ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "45/45 - 0s - loss: 0.0882 - accuracy: 0.9756 - 117ms/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "45/45 - 0s - loss: 0.0883 - accuracy: 0.9758 - 116ms/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "45/45 - 0s - loss: 0.0873 - accuracy: 0.9754 - 106ms/epoch - 2ms/step\n",
      "Epoch 90/200\n",
      "45/45 - 0s - loss: 0.0867 - accuracy: 0.9751 - 138ms/epoch - 3ms/step\n",
      "Epoch 91/200\n",
      "45/45 - 0s - loss: 0.0851 - accuracy: 0.9763 - 100ms/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "45/45 - 0s - loss: 0.0838 - accuracy: 0.9774 - 102ms/epoch - 2ms/step\n",
      "Epoch 93/200\n",
      "45/45 - 0s - loss: 0.0835 - accuracy: 0.9778 - 94ms/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "45/45 - 0s - loss: 0.0834 - accuracy: 0.9774 - 88ms/epoch - 2ms/step\n",
      "Epoch 95/200\n",
      "45/45 - 0s - loss: 0.0822 - accuracy: 0.9787 - 162ms/epoch - 4ms/step\n",
      "Epoch 96/200\n",
      "45/45 - 0s - loss: 0.0821 - accuracy: 0.9778 - 102ms/epoch - 2ms/step\n",
      "Epoch 97/200\n",
      "45/45 - 0s - loss: 0.0797 - accuracy: 0.9787 - 104ms/epoch - 2ms/step\n",
      "Epoch 98/200\n",
      "45/45 - 0s - loss: 0.0796 - accuracy: 0.9792 - 108ms/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "45/45 - 0s - loss: 0.0787 - accuracy: 0.9798 - 97ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "45/45 - 0s - loss: 0.0776 - accuracy: 0.9792 - 88ms/epoch - 2ms/step\n",
      "Epoch 101/200\n",
      "45/45 - 0s - loss: 0.0771 - accuracy: 0.9805 - 99ms/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "45/45 - 0s - loss: 0.0764 - accuracy: 0.9812 - 115ms/epoch - 3ms/step\n",
      "Epoch 103/200\n",
      "45/45 - 0s - loss: 0.0765 - accuracy: 0.9785 - 89ms/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "45/45 - 0s - loss: 0.0751 - accuracy: 0.9807 - 88ms/epoch - 2ms/step\n",
      "Epoch 105/200\n",
      "45/45 - 0s - loss: 0.0735 - accuracy: 0.9830 - 76ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "45/45 - 0s - loss: 0.0745 - accuracy: 0.9812 - 69ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "45/45 - 0s - loss: 0.0723 - accuracy: 0.9828 - 84ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "45/45 - 0s - loss: 0.0727 - accuracy: 0.9823 - 116ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "45/45 - 0s - loss: 0.0722 - accuracy: 0.9832 - 124ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "45/45 - 0s - loss: 0.0710 - accuracy: 0.9830 - 154ms/epoch - 3ms/step\n",
      "Epoch 111/200\n",
      "45/45 - 0s - loss: 0.0702 - accuracy: 0.9845 - 314ms/epoch - 7ms/step\n",
      "Epoch 112/200\n",
      "45/45 - 0s - loss: 0.0694 - accuracy: 0.9825 - 293ms/epoch - 7ms/step\n",
      "Epoch 113/200\n",
      "45/45 - 0s - loss: 0.0684 - accuracy: 0.9843 - 200ms/epoch - 4ms/step\n",
      "Epoch 114/200\n",
      "45/45 - 0s - loss: 0.0697 - accuracy: 0.9839 - 199ms/epoch - 4ms/step\n",
      "Epoch 115/200\n",
      "45/45 - 0s - loss: 0.0685 - accuracy: 0.9821 - 215ms/epoch - 5ms/step\n",
      "Epoch 116/200\n",
      "45/45 - 0s - loss: 0.0671 - accuracy: 0.9857 - 183ms/epoch - 4ms/step\n",
      "Epoch 117/200\n",
      "45/45 - 0s - loss: 0.0668 - accuracy: 0.9834 - 236ms/epoch - 5ms/step\n",
      "Epoch 118/200\n",
      "45/45 - 0s - loss: 0.0657 - accuracy: 0.9868 - 288ms/epoch - 6ms/step\n",
      "Epoch 119/200\n",
      "45/45 - 0s - loss: 0.0662 - accuracy: 0.9841 - 301ms/epoch - 7ms/step\n",
      "Epoch 120/200\n",
      "45/45 - 0s - loss: 0.0651 - accuracy: 0.9852 - 265ms/epoch - 6ms/step\n",
      "Epoch 121/200\n",
      "45/45 - 0s - loss: 0.0643 - accuracy: 0.9848 - 240ms/epoch - 5ms/step\n",
      "Epoch 122/200\n",
      "45/45 - 0s - loss: 0.0647 - accuracy: 0.9845 - 225ms/epoch - 5ms/step\n",
      "Epoch 123/200\n",
      "45/45 - 0s - loss: 0.0634 - accuracy: 0.9857 - 219ms/epoch - 5ms/step\n",
      "Epoch 124/200\n",
      "45/45 - 0s - loss: 0.0626 - accuracy: 0.9854 - 179ms/epoch - 4ms/step\n",
      "Epoch 125/200\n",
      "45/45 - 0s - loss: 0.0629 - accuracy: 0.9861 - 248ms/epoch - 6ms/step\n",
      "Epoch 126/200\n",
      "45/45 - 0s - loss: 0.0615 - accuracy: 0.9857 - 163ms/epoch - 4ms/step\n",
      "Epoch 127/200\n",
      "45/45 - 0s - loss: 0.0610 - accuracy: 0.9863 - 198ms/epoch - 4ms/step\n",
      "Epoch 128/200\n",
      "45/45 - 0s - loss: 0.0604 - accuracy: 0.9868 - 178ms/epoch - 4ms/step\n",
      "Epoch 129/200\n",
      "45/45 - 0s - loss: 0.0603 - accuracy: 0.9872 - 129ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "45/45 - 0s - loss: 0.0605 - accuracy: 0.9863 - 140ms/epoch - 3ms/step\n",
      "Epoch 131/200\n",
      "45/45 - 0s - loss: 0.0589 - accuracy: 0.9868 - 117ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "45/45 - 0s - loss: 0.0587 - accuracy: 0.9872 - 86ms/epoch - 2ms/step\n",
      "Epoch 133/200\n",
      "45/45 - 0s - loss: 0.0590 - accuracy: 0.9875 - 84ms/epoch - 2ms/step\n",
      "Epoch 134/200\n",
      "45/45 - 0s - loss: 0.0570 - accuracy: 0.9884 - 91ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "45/45 - 0s - loss: 0.0576 - accuracy: 0.9870 - 72ms/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "45/45 - 0s - loss: 0.0572 - accuracy: 0.9868 - 70ms/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "45/45 - 0s - loss: 0.0569 - accuracy: 0.9879 - 72ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "45/45 - 0s - loss: 0.0564 - accuracy: 0.9863 - 73ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "45/45 - 0s - loss: 0.0559 - accuracy: 0.9866 - 177ms/epoch - 4ms/step\n",
      "Epoch 140/200\n",
      "45/45 - 0s - loss: 0.0561 - accuracy: 0.9877 - 149ms/epoch - 3ms/step\n",
      "Epoch 141/200\n",
      "45/45 - 0s - loss: 0.0543 - accuracy: 0.9875 - 118ms/epoch - 3ms/step\n",
      "Epoch 142/200\n",
      "45/45 - 0s - loss: 0.0543 - accuracy: 0.9884 - 156ms/epoch - 3ms/step\n",
      "Epoch 143/200\n",
      "45/45 - 0s - loss: 0.0540 - accuracy: 0.9888 - 128ms/epoch - 3ms/step\n",
      "Epoch 144/200\n",
      "45/45 - 0s - loss: 0.0529 - accuracy: 0.9877 - 93ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "45/45 - 0s - loss: 0.0536 - accuracy: 0.9879 - 83ms/epoch - 2ms/step\n",
      "Epoch 146/200\n",
      "45/45 - 0s - loss: 0.0524 - accuracy: 0.9888 - 94ms/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "45/45 - 0s - loss: 0.0523 - accuracy: 0.9884 - 122ms/epoch - 3ms/step\n",
      "Epoch 148/200\n",
      "45/45 - 0s - loss: 0.0530 - accuracy: 0.9875 - 120ms/epoch - 3ms/step\n",
      "Epoch 149/200\n",
      "45/45 - 0s - loss: 0.0522 - accuracy: 0.9884 - 128ms/epoch - 3ms/step\n",
      "Epoch 150/200\n",
      "45/45 - 0s - loss: 0.0502 - accuracy: 0.9897 - 149ms/epoch - 3ms/step\n",
      "Epoch 151/200\n",
      "45/45 - 0s - loss: 0.0513 - accuracy: 0.9879 - 163ms/epoch - 4ms/step\n",
      "Epoch 152/200\n",
      "45/45 - 0s - loss: 0.0508 - accuracy: 0.9881 - 137ms/epoch - 3ms/step\n",
      "Epoch 153/200\n",
      "45/45 - 0s - loss: 0.0504 - accuracy: 0.9884 - 223ms/epoch - 5ms/step\n",
      "Epoch 154/200\n",
      "45/45 - 0s - loss: 0.0494 - accuracy: 0.9899 - 208ms/epoch - 5ms/step\n",
      "Epoch 155/200\n",
      "45/45 - 0s - loss: 0.0496 - accuracy: 0.9895 - 148ms/epoch - 3ms/step\n",
      "Epoch 156/200\n",
      "45/45 - 0s - loss: 0.0487 - accuracy: 0.9890 - 200ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "45/45 - 0s - loss: 0.0489 - accuracy: 0.9897 - 179ms/epoch - 4ms/step\n",
      "Epoch 158/200\n",
      "45/45 - 0s - loss: 0.0481 - accuracy: 0.9899 - 202ms/epoch - 4ms/step\n",
      "Epoch 159/200\n",
      "45/45 - 0s - loss: 0.0478 - accuracy: 0.9884 - 264ms/epoch - 6ms/step\n",
      "Epoch 160/200\n",
      "45/45 - 0s - loss: 0.0481 - accuracy: 0.9888 - 232ms/epoch - 5ms/step\n",
      "Epoch 161/200\n",
      "45/45 - 0s - loss: 0.0468 - accuracy: 0.9901 - 246ms/epoch - 5ms/step\n",
      "Epoch 162/200\n",
      "45/45 - 0s - loss: 0.0458 - accuracy: 0.9901 - 237ms/epoch - 5ms/step\n",
      "Epoch 163/200\n",
      "45/45 - 0s - loss: 0.0459 - accuracy: 0.9910 - 217ms/epoch - 5ms/step\n",
      "Epoch 164/200\n",
      "45/45 - 0s - loss: 0.0450 - accuracy: 0.9899 - 243ms/epoch - 5ms/step\n",
      "Epoch 165/200\n",
      "45/45 - 0s - loss: 0.0459 - accuracy: 0.9901 - 184ms/epoch - 4ms/step\n",
      "Epoch 166/200\n",
      "45/45 - 0s - loss: 0.0451 - accuracy: 0.9901 - 144ms/epoch - 3ms/step\n",
      "Epoch 167/200\n",
      "45/45 - 0s - loss: 0.0452 - accuracy: 0.9908 - 139ms/epoch - 3ms/step\n",
      "Epoch 168/200\n",
      "45/45 - 0s - loss: 0.0451 - accuracy: 0.9906 - 165ms/epoch - 4ms/step\n",
      "Epoch 169/200\n",
      "45/45 - 0s - loss: 0.0441 - accuracy: 0.9904 - 218ms/epoch - 5ms/step\n",
      "Epoch 170/200\n",
      "45/45 - 0s - loss: 0.0440 - accuracy: 0.9908 - 195ms/epoch - 4ms/step\n",
      "Epoch 171/200\n",
      "45/45 - 0s - loss: 0.0434 - accuracy: 0.9913 - 227ms/epoch - 5ms/step\n",
      "Epoch 172/200\n",
      "45/45 - 0s - loss: 0.0434 - accuracy: 0.9908 - 262ms/epoch - 6ms/step\n",
      "Epoch 173/200\n",
      "45/45 - 0s - loss: 0.0430 - accuracy: 0.9906 - 187ms/epoch - 4ms/step\n",
      "Epoch 174/200\n",
      "45/45 - 0s - loss: 0.0426 - accuracy: 0.9897 - 161ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "45/45 - 0s - loss: 0.0423 - accuracy: 0.9897 - 135ms/epoch - 3ms/step\n",
      "Epoch 176/200\n",
      "45/45 - 0s - loss: 0.0419 - accuracy: 0.9915 - 115ms/epoch - 3ms/step\n",
      "Epoch 177/200\n",
      "45/45 - 0s - loss: 0.0425 - accuracy: 0.9901 - 167ms/epoch - 4ms/step\n",
      "Epoch 178/200\n",
      "45/45 - 0s - loss: 0.0406 - accuracy: 0.9926 - 251ms/epoch - 6ms/step\n",
      "Epoch 179/200\n",
      "45/45 - 0s - loss: 0.0407 - accuracy: 0.9917 - 198ms/epoch - 4ms/step\n",
      "Epoch 180/200\n",
      "45/45 - 0s - loss: 0.0404 - accuracy: 0.9924 - 204ms/epoch - 5ms/step\n",
      "Epoch 181/200\n",
      "45/45 - 0s - loss: 0.0409 - accuracy: 0.9901 - 199ms/epoch - 4ms/step\n",
      "Epoch 182/200\n",
      "45/45 - 0s - loss: 0.0403 - accuracy: 0.9919 - 221ms/epoch - 5ms/step\n",
      "Epoch 183/200\n",
      "45/45 - 0s - loss: 0.0401 - accuracy: 0.9910 - 155ms/epoch - 3ms/step\n",
      "Epoch 184/200\n",
      "45/45 - 0s - loss: 0.0393 - accuracy: 0.9910 - 138ms/epoch - 3ms/step\n",
      "Epoch 185/200\n",
      "45/45 - 0s - loss: 0.0391 - accuracy: 0.9906 - 128ms/epoch - 3ms/step\n",
      "Epoch 186/200\n",
      "45/45 - 0s - loss: 0.0390 - accuracy: 0.9895 - 140ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "45/45 - 0s - loss: 0.0389 - accuracy: 0.9908 - 118ms/epoch - 3ms/step\n",
      "Epoch 188/200\n",
      "45/45 - 0s - loss: 0.0380 - accuracy: 0.9924 - 133ms/epoch - 3ms/step\n",
      "Epoch 189/200\n",
      "45/45 - 0s - loss: 0.0384 - accuracy: 0.9908 - 187ms/epoch - 4ms/step\n",
      "Epoch 190/200\n",
      "45/45 - 0s - loss: 0.0372 - accuracy: 0.9917 - 106ms/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "45/45 - 0s - loss: 0.0369 - accuracy: 0.9924 - 81ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "45/45 - 0s - loss: 0.0376 - accuracy: 0.9917 - 77ms/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "45/45 - 0s - loss: 0.0364 - accuracy: 0.9910 - 77ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "45/45 - 0s - loss: 0.0371 - accuracy: 0.9922 - 85ms/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "45/45 - 0s - loss: 0.0366 - accuracy: 0.9910 - 81ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "45/45 - 0s - loss: 0.0359 - accuracy: 0.9915 - 85ms/epoch - 2ms/step\n",
      "Epoch 197/200\n",
      "45/45 - 0s - loss: 0.0353 - accuracy: 0.9917 - 76ms/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "45/45 - 0s - loss: 0.0362 - accuracy: 0.9917 - 71ms/epoch - 2ms/step\n",
      "Epoch 199/200\n",
      "45/45 - 0s - loss: 0.0346 - accuracy: 0.9928 - 83ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "45/45 - 0s - loss: 0.0343 - accuracy: 0.9919 - 75ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16985dc78d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_onehot, epochs=200, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tóm tắt các thông tin sau khi train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                144       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 820 (3.20 KB)\n",
      "Trainable params: 820 (3.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.7632876e-11, 6.6709064e-02, 9.3329102e-01, 1.4771399e-20],\n",
       "       [3.4194378e-09, 1.0000000e+00, 4.0096215e-11, 2.5778813e-23],\n",
       "       [2.8403844e-12, 9.5262110e-01, 4.7378846e-02, 3.2443965e-23],\n",
       "       ...,\n",
       "       [7.9045836e-17, 1.0000000e+00, 1.2282537e-22, 0.0000000e+00],\n",
       "       [4.7165341e-07, 1.3885695e-02, 1.3058444e-02, 9.7305536e-01],\n",
       "       [1.7211455e-04, 9.9981350e-01, 6.5514828e-06, 7.8971716e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với mỗi hàng trong ma trận trên chính là xác xuất của từng class khi model dự đoán 1 input.\\\n",
    "Với mỗi hàng ta sẽ lấy index của element có giá trị lớn nhất, index này cũng chính là class mà model dự đoán cho 1 input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 1, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy rằng model FFNN này có tỉ lệ dự đóan của model này ở mức cao lên đến 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       219\n",
      "           1       0.97      0.99      0.98       874\n",
      "           2       0.94      0.85      0.90       110\n",
      "           3       0.99      0.99      0.99       285\n",
      "\n",
      "    accuracy                           0.97      1488\n",
      "   macro avg       0.97      0.95      0.96      1488\n",
      "weighted avg       0.97      0.97      0.97      1488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng early stopping để tránh overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chọn feature time làm dữ liệu, target vẫn là traffic situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df\n",
    "df_tmp['Time'] = pd.to_datetime(df_tmp['Time'])\n",
    "df_tmp['Time'] = df_tmp['Time'].apply(lambda x: x.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tmp[['Time']]\n",
    "y = df_tmp['Traffic Situation'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tách dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.transform(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo model RNN với Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.LSTM(128, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 5s 17ms/step - loss: 1.3705 - accuracy: 0.5902 - val_loss: 1.3518 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.3400 - accuracy: 0.6011 - val_loss: 1.3204 - val_accuracy: 0.6280\n",
      "Epoch 3/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.3120 - accuracy: 0.6011 - val_loss: 1.2911 - val_accuracy: 0.6280\n",
      "Epoch 4/200\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.2861 - accuracy: 0.6011 - val_loss: 1.2646 - val_accuracy: 0.6280\n",
      "Epoch 5/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.2627 - accuracy: 0.6011 - val_loss: 1.2401 - val_accuracy: 0.6280\n",
      "Epoch 6/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.2413 - accuracy: 0.6011 - val_loss: 1.2183 - val_accuracy: 0.6280\n",
      "Epoch 7/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.2221 - accuracy: 0.6011 - val_loss: 1.1980 - val_accuracy: 0.6280\n",
      "Epoch 8/200\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2048 - accuracy: 0.6011 - val_loss: 1.1800 - val_accuracy: 0.6280\n",
      "Epoch 9/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.1895 - accuracy: 0.6011 - val_loss: 1.1637 - val_accuracy: 0.6280\n",
      "Epoch 10/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1758 - accuracy: 0.6011 - val_loss: 1.1497 - val_accuracy: 0.6280\n",
      "Epoch 11/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 1.1637 - accuracy: 0.6011 - val_loss: 1.1369 - val_accuracy: 0.6280\n",
      "Epoch 12/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.1529 - accuracy: 0.6011 - val_loss: 1.1257 - val_accuracy: 0.6280\n",
      "Epoch 13/200\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1434 - accuracy: 0.6011 - val_loss: 1.1155 - val_accuracy: 0.6280\n",
      "Epoch 14/200\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.1351 - accuracy: 0.6011 - val_loss: 1.1065 - val_accuracy: 0.6280\n",
      "Epoch 15/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1277 - accuracy: 0.6011 - val_loss: 1.0989 - val_accuracy: 0.6280\n",
      "Epoch 16/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1213 - accuracy: 0.6011 - val_loss: 1.0920 - val_accuracy: 0.6280\n",
      "Epoch 17/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.1157 - accuracy: 0.6011 - val_loss: 1.0860 - val_accuracy: 0.6280\n",
      "Epoch 18/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.6011 - val_loss: 1.0807 - val_accuracy: 0.6280\n",
      "Epoch 19/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1064 - accuracy: 0.6011 - val_loss: 1.0760 - val_accuracy: 0.6280\n",
      "Epoch 20/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1026 - accuracy: 0.6011 - val_loss: 1.0720 - val_accuracy: 0.6280\n",
      "Epoch 21/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.6011 - val_loss: 1.0684 - val_accuracy: 0.6280\n",
      "Epoch 22/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0964 - accuracy: 0.6011 - val_loss: 1.0652 - val_accuracy: 0.6280\n",
      "Epoch 23/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0938 - accuracy: 0.6011 - val_loss: 1.0626 - val_accuracy: 0.6280\n",
      "Epoch 24/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0916 - accuracy: 0.6011 - val_loss: 1.0601 - val_accuracy: 0.6280\n",
      "Epoch 25/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 1.0896 - accuracy: 0.6011 - val_loss: 1.0580 - val_accuracy: 0.6280\n",
      "Epoch 26/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0878 - accuracy: 0.6011 - val_loss: 1.0562 - val_accuracy: 0.6280\n",
      "Epoch 27/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0863 - accuracy: 0.6011 - val_loss: 1.0546 - val_accuracy: 0.6280\n",
      "Epoch 28/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0849 - accuracy: 0.6011 - val_loss: 1.0531 - val_accuracy: 0.6280\n",
      "Epoch 29/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0837 - accuracy: 0.6011 - val_loss: 1.0521 - val_accuracy: 0.6280\n",
      "Epoch 30/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0826 - accuracy: 0.6011 - val_loss: 1.0509 - val_accuracy: 0.6280\n",
      "Epoch 31/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0816 - accuracy: 0.6011 - val_loss: 1.0499 - val_accuracy: 0.6280\n",
      "Epoch 32/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0808 - accuracy: 0.6011 - val_loss: 1.0491 - val_accuracy: 0.6280\n",
      "Epoch 33/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0800 - accuracy: 0.6011 - val_loss: 1.0485 - val_accuracy: 0.6280\n",
      "Epoch 34/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0793 - accuracy: 0.6011 - val_loss: 1.0477 - val_accuracy: 0.6280\n",
      "Epoch 35/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0787 - accuracy: 0.6011 - val_loss: 1.0473 - val_accuracy: 0.6280\n",
      "Epoch 36/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 1.0781 - accuracy: 0.6011 - val_loss: 1.0468 - val_accuracy: 0.6280\n",
      "Epoch 37/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0776 - accuracy: 0.6011 - val_loss: 1.0464 - val_accuracy: 0.6280\n",
      "Epoch 38/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0772 - accuracy: 0.6011 - val_loss: 1.0460 - val_accuracy: 0.6280\n",
      "Epoch 39/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0768 - accuracy: 0.6011 - val_loss: 1.0458 - val_accuracy: 0.6280\n",
      "Epoch 40/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0765 - accuracy: 0.6011 - val_loss: 1.0454 - val_accuracy: 0.6280\n",
      "Epoch 41/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0761 - accuracy: 0.6011 - val_loss: 1.0452 - val_accuracy: 0.6280\n",
      "Epoch 42/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0758 - accuracy: 0.6011 - val_loss: 1.0451 - val_accuracy: 0.6280\n",
      "Epoch 43/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0756 - accuracy: 0.6011 - val_loss: 1.0450 - val_accuracy: 0.6280\n",
      "Epoch 44/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0754 - accuracy: 0.6011 - val_loss: 1.0448 - val_accuracy: 0.6280\n",
      "Epoch 45/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0752 - accuracy: 0.6011 - val_loss: 1.0447 - val_accuracy: 0.6280\n",
      "Epoch 46/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0750 - accuracy: 0.6011 - val_loss: 1.0446 - val_accuracy: 0.6280\n",
      "Epoch 47/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0749 - accuracy: 0.6011 - val_loss: 1.0446 - val_accuracy: 0.6280\n",
      "Epoch 48/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 1.0747 - accuracy: 0.6011 - val_loss: 1.0445 - val_accuracy: 0.6280\n",
      "Epoch 49/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0746 - accuracy: 0.6011 - val_loss: 1.0444 - val_accuracy: 0.6280\n",
      "Epoch 50/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0745 - accuracy: 0.6011 - val_loss: 1.0444 - val_accuracy: 0.6280\n",
      "Epoch 51/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0744 - accuracy: 0.6011 - val_loss: 1.0446 - val_accuracy: 0.6280\n",
      "Epoch 52/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0743 - accuracy: 0.6011 - val_loss: 1.0444 - val_accuracy: 0.6280\n",
      "Epoch 53/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0742 - accuracy: 0.6011 - val_loss: 1.0444 - val_accuracy: 0.6280\n",
      "Epoch 54/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0742 - accuracy: 0.6011 - val_loss: 1.0444 - val_accuracy: 0.6280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16992953e90>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), batch_size=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá kết quả sau khi train.\\\n",
    "Nhìn chung RNN không dự đoán chính xác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/38 [==================>...........] - ETA: 0s - loss: 1.0648 - accuracy: 0.6112"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.6280\n",
      "Loss: 1.0443623065948486, Accuracy: 0.6280436515808105\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       216\n",
      "           1       0.00      0.00      0.00        81\n",
      "           2       0.00      0.00      0.00       146\n",
      "           3       0.63      1.00      0.77       748\n",
      "\n",
      "    accuracy                           0.63      1191\n",
      "   macro avg       0.16      0.25      0.19      1191\n",
      "weighted avg       0.39      0.63      0.48      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
